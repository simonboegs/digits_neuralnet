
wow i just deleted everything in this file. nice.

backprop equations for:
	activation (hidden layer): doesn't matter
	activation (last layer): soft max
	cost function: cross-entropy
https://towardsdatascience.com/deriving-backpropagation-with-cross-entropy-loss-d24811edeaf9

wed
[x] write test file for activation functions
[x] write tests for init functions

thurs
[x] implement forward prop

fri
[x] verify forward prop

sat
[x] start on backprop
[x]		implemented errors
[x]		verified errors
[x]		implemented gradient and mean_gradient calculations

sun
[x] verify gradient
[ ] verify mean_gradient
[ ] implement update_weights_biases
[ ] verify update_weights_biases

