
wow i just deleted everything in this file. nice.

backprop equations for:
	activation (hidden layer): doesn't matter
	activation (last layer): soft max
	cost function: cross-entropy
https://towardsdatascience.com/deriving-backpropagation-with-cross-entropy-loss-d24811edeaf9

wed
[x] write test file for activation functions
[x] write tests for init functions

thurs
[x] implement forward prop

fri
[x] verify forward prop

sat
[x] start on backprop
[x]		implemented errors
[x]		verified errors
[x]		implemented gradient and mean_gradient calculations

sun
- implemented train_mini_batch (not tested yet), includes
	- calc gradient
	- calc mean gradient
	- update weights and biases
